{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208b68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05be3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 1729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34daebf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>43327.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>35841.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27645.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>29023.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Driving_License  Region_Code  Previously_Insured Vehicle_Age  \\\n",
       "0    Male   22                1          7.0                   1    < 1 Year   \n",
       "1    Male   42                1         28.0                   0    1-2 Year   \n",
       "2  Female   66                1         33.0                   0    1-2 Year   \n",
       "3  Female   22                1         33.0                   0    < 1 Year   \n",
       "4    Male   28                1         46.0                   1    < 1 Year   \n",
       "\n",
       "  Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  Response  \n",
       "0             No          2630.0                 152.0       16         0  \n",
       "1            Yes         43327.0                  26.0      135         0  \n",
       "2            Yes         35841.0                 124.0      253         0  \n",
       "3             No         27645.0                 152.0       69         0  \n",
       "4             No         29023.0                 152.0      211         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(r'../datasets/aug_train.csv')\n",
    "original_df = original_df.loc[:, ~original_df.columns.isin(['id'])]\n",
    "original_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff456d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(df, preds, trgts, encs=None):\n",
    "    columns = list(df.columns)\n",
    "    X = np.empty(df[[i for k, v in preds.items() for i in v]].shape)\n",
    "    Y = np.empty(df[[i for k, v in trgts.items() for i in v]].shape)\n",
    "\n",
    "    for i, col in enumerate(preds['continuous']):\n",
    "        X[:, columns.index(col)] = df[col]\n",
    "    for i, col in enumerate(trgts['continuous']):\n",
    "        Y[:, i] = df[col]\n",
    "\n",
    "    if encs is None:\n",
    "        encs = dict()\n",
    "    for i, col in enumerate(preds['categorical']):\n",
    "        if col not in encs:\n",
    "            enc = LabelEncoder()\n",
    "            enc.fit(df[col])\n",
    "            encs[col] = enc\n",
    "        else:\n",
    "            enc = encs[col]\n",
    "        X[:, columns.index(col)] = enc.transform(df[col])\n",
    "    for i, col in enumerate(trgts['categorical']):\n",
    "        if col not in encs:\n",
    "            enc = LabelEncoder()\n",
    "            enc.fit(df[col])\n",
    "            encs[col] = enc\n",
    "        else:\n",
    "            enc = encs[col]\n",
    "        Y[:, i] = enc.transform(df[col])\n",
    "\n",
    "    return X, Y, encs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2031009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Vishvig/Desktop/Education/UoB/.uob/envs/data_analytics/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "predictors = {'categorical': ['Gender', 'Age', 'Driving_License',\n",
    "                                  'Region_Code', 'Previously_Insured', 'Vehicle_Age',\n",
    "                                  'Vehicle_Damage', 'Policy_Sales_Channel', 'Vintage'],\n",
    "              'continuous': ['Annual_Premium']}\n",
    "targets = {'categorical': ['Response'],\n",
    "           'continuous': []}\n",
    "pre_process_model = joblib.load(r\"../model/logistic_regression_pre_process.pkl\")\n",
    "original_df = original_df[pre_process_model['columns']]\n",
    "_X, _Y, _encs = to_numpy(original_df,\n",
    "                         preds=predictors,\n",
    "                         trgts=targets,\n",
    "                         encs=pre_process_model[\"encs\"])\n",
    "joined = np.hstack((_X, _Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c64c861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   1.   7.   1.   1.   0. 146.   6.   0.]\n",
      " [  1.  22.   1.  28.   0.   0.   1.  24. 125.   0.]\n",
      " [  0.  46.   1.  33.   0.   0.   1. 119. 243.   0.]\n",
      " [  0.   2.   1.  33.   0.   1.   0. 146.  59.   0.]\n",
      " [  1.   8.   1.  46.   1.   1.   0. 146. 201.   0.]\n",
      " [  0.   5.   1.  25.   1.   1.   0. 146.  13.   0.]\n",
      " [  1.  31.   1.   8.   0.   0.   1.  24. 199.   0.]\n",
      " [  1.  18.   1.  28.   1.   0.   0.  24.  41.   0.]\n",
      " [  0.  25.   1.  28.   0.   0.   1. 119. 252.   0.]\n",
      " [  1.  22.   1.  28.   0.   0.   1. 117. 207.   1.]\n",
      " [  1.   5.   1.   8.   1.   1.   0. 146.  63.   0.]\n",
      " [  0.   6.   1.   8.   1.   1.   0. 146.   2.   0.]\n",
      " [  1.  13.   1.  28.   0.   1.   1. 117. 155.   1.]\n",
      " [  1.   5.   1.  28.   1.   1.   0. 146.  24.   0.]\n",
      " [  1.  22.   1.  28.   0.   0.   1. 119. 253.   1.]\n",
      " [  1.  25.   1.  41.   0.   0.   1.  24. 145.   1.]\n",
      " [  0.  56.   1.  28.   0.   2.   0. 152. 141.   0.]\n",
      " [  1.   3.   1.  28.   1.   1.   0. 146. 166.   0.]\n",
      " [  1.  29.   1.  28.   0.   0.   1.  24. 167.   0.]\n",
      " [  1.   2.   1.  39.   1.   1.   0. 146. 230.   0.]]\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = original_df.shape\n",
    "\n",
    "features = list()\n",
    "features.extend(predictors['categorical'])\n",
    "features.extend(targets['categorical'])\n",
    "\n",
    "X = np.zeros((n_samples, len(features)))\n",
    "columns = list(pre_process_model['columns'])\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    X[:, i] = joined[:, columns.index(feature)]\n",
    "print(X[0:20])\n",
    "X = X[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac5cd1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.14646006, 0.25102622, 0.22633065, 0.37618307]), array([0.05727625, 0.34162036, 0.24262204, 0.35848136]), array([0.1438775 , 0.46845686, 0.33328421, 0.05438143]), array([0.03031333, 0.36843434, 0.28425282, 0.31699951]), array([0.08022573, 0.10692369, 0.38686628, 0.42598431]), array([0.48481169, 0.16491853, 0.104289  , 0.24598078]), array([0.21796423, 0.40854446, 0.05289353, 0.32059778]), array([0.07511683, 0.37248568, 0.42524698, 0.12715052]), array([0.31115556, 0.22200934, 0.42238574, 0.04444936]), array([0.36277427, 0.36231836, 0.09509484, 0.17981252])]\n"
     ]
    }
   ],
   "source": [
    "from mnmm import MNMM\n",
    "\n",
    "model = MNMM(n_components=4,\n",
    "             random_state = 1729,\n",
    "             max_iter=10,\n",
    "             rtol=1e-3)\n",
    "model.fit(X)\n",
    "print(model.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d6878b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying tol: 1e-06\n",
      "Trying max_iter: 10\n",
      "0\n",
      "&&&&& {'train_score': [0.15373551927171952, 0.08356000331472008, 0.10772359744983122, 0.08716687013246233, 0.1346382662304222], 'test_score': [0.09811982507967756, 0.2936062147214907, 0.29230363264301085, 0.2754013333289694, 0.15243063899598538]}\n",
      "1\n",
      "&&&&& {'train_score': [0.22257366450073202, 0.28074600831168567, 0.3134342335423694, 0.3030896279924714, 0.35254176596288], 'test_score': [0.41948019358251476, 0.6220976776067272, 0.7293928439023941, 0.5876482264178245, 0.544230205949346]}\n",
      "2\n",
      "&&&&& {'train_score': [0.33915749274934076, 0.36512589946315194, 0.37631067365663423, 0.30769125637477385, 0.3772989029904614], 'test_score': [0.44359306374068785, 0.7788485241757561, 0.713887983315247, 0.7754304460776971, 0.7607478146048823]}\n",
      "3\n",
      "&&&&& {'train_score': [0.3675062956977295, 0.48386289066846405, 0.4146877951916103, 0.4645038301776721, 0.283616046403024], 'test_score': [0.8386726403478582, 0.9235613587698844, 1.0477499782510016, 1.0972652501952906, 0.7978694332762525]}\n",
      "4\n",
      "&&&&& {'train_score': [0.5911210135168063, 0.4971596205232449, 0.4663561809700987, 0.4984938795001541, 0.42228623516460295], 'test_score': [0.6318778040714167, 1.0806699297576394, 1.3199495302036774, 1.1123473303620453, 1.0805393865842055]}\n",
      "5\n",
      "&&&&& {'train_score': [1.0911150831456524, 1.0670740530870102, 1.028345633177378, 1.0235266530120481, 1.0380021017680132], 'test_score': [1.345907527648549, 1.8569047376818295, 2.003051134477937, 1.8501140817270085, 1.8969899130563]}\n",
      "6\n",
      "&&&&& {'train_score': [0.7041014405127649, 0.5192495622746837, 0.40487603055858246, 0.5186682995341676, 0.6454722655820873], 'test_score': [0.8708466431913912, 1.530534802527636, 1.05189539427791, 1.5530196013253819, 1.1192684613650554]}\n",
      "7\n",
      "&&&&& {'train_score': [0.3875605563988948, 0.5691100408697563, 0.4969995878656087, 0.5383296014555101, 0.5248317110861951], 'test_score': [0.9177795512899736, 1.0895423836808509, 1.2972880033835956, 1.3782115281346077, 1.1753519428019255]}\n",
      "8\n",
      "&&&&& {'train_score': [0.6400581029438542, 0.5861519138599727, 0.5538846626491547, 0.5589885568651407, 0.6411250872423884], 'test_score': [0.9864999180319028, 1.559993784548248, 1.5414391214364929, 1.5923623965529197, 1.224765113987511]}\n",
      "9\n",
      "&&&&& {'train_score': [0.7046382248474637, 0.5760784337704208, 0.4232878625293522, 0.5837699044822107, 0.6977118948097185], 'test_score': [1.0332177618159284, 1.6627543376512313, 1.4556495048316478, 1.6797268128382614, 1.3282805650404086]}\n",
      "10\n",
      "&&&&& {'train_score': [1.1508747369814172, 0.8826895195463542, 0.8595154506908274, 0.8376151416086192, 1.0902444054346276], 'test_score': [0.6794718235931703, 2.3760134978803986, 2.4799277630664633, 2.1619535081290713, 1.666327339166993]}\n",
      "11\n",
      "&&&&& {'train_score': [1.5740896244224882, 1.4869915688882103, 1.3810310699086887, 1.3670959812967172, 1.4352046529069202], 'test_score': [1.6410189438199048, 2.369375821010626, 2.6839042163820626, 2.451463338081928, 2.664815109586799]}\n",
      "12\n",
      "&&&&& {'train_score': [1.981622433621509, 1.7366757464518812, 1.7262859541874043, 1.5360862294115316, 1.745876404215231], 'test_score': [2.0985387606538515, 3.025451877265874, 3.0997951788551386, 2.6082877853066644, 3.0865442860648202]}\n",
      "13\n",
      "&&&&& {'train_score': [2.229609907655276, 1.811140388292208, 1.4926050408304297, 1.5065287826808562, 1.7126015806187482], 'test_score': [1.9825749323502397, 2.8394520679847934, 3.253599755333423, 2.915509144627731, 3.2634904630473454]}\n",
      "valid max_iter from training: 10\n",
      "valid tol from training: 1e-06\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def cross_validation(model, X, cv=5):\n",
    "    train_scores = list()\n",
    "    val_scores = list()\n",
    "    _cv = KFold(n_splits=cv,random_state=rs, shuffle=True)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('error', category=ConvergenceWarning)\n",
    "        try:\n",
    "            for train_index, val_index in _cv.split(X):\n",
    "                Xtrain, Xval = X[train_index], X[val_index]\n",
    "                model.fit(Xtrain)\n",
    "                train_score = model.score_samples(Xtrain)\n",
    "                val_score = model.score_samples(Xval)\n",
    "#                 print(f'%%%%{train_score}, {val_score}')\n",
    "                train_scores.append(np.sum(train_score))\n",
    "                val_scores.append(np.sum(val_score))\n",
    "        except ValueError as e:\n",
    "            raise ValueError(e)\n",
    "        except ConvergenceWarning as e:\n",
    "            raise ConvergenceWarning(e)\n",
    "        except Exception as e:\n",
    "            raise Exception(e)\n",
    "    return {'train_score': train_scores, 'test_score': val_scores}\n",
    "\n",
    "\n",
    "def train(X, **kwargs):\n",
    "    trainNLL = []\n",
    "    validNLL = []\n",
    "    nvalid = []\n",
    "    valid_max_iter = None\n",
    "    valid_tol = None\n",
    "    \n",
    "    max_iters = kwargs.get('max_iters', None)\n",
    "    tols = kwargs.get('tols', None)\n",
    "    nvals = kwargs.get('nvals', None)\n",
    "    \n",
    "    if max_iters is None:\n",
    "        max_iters = [10, 100, 1000, 10000, 100000]\n",
    "    if tols is None:\n",
    "        tols = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "    if nvals is None:\n",
    "        nvals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40 , 50]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('error', category=ConvergenceWarning)\n",
    "        for tol in tols:\n",
    "            if valid_tol is None:\n",
    "                valid_tol = tol\n",
    "            else:\n",
    "                print(f\"valid tol from training: {valid_tol}\")\n",
    "                break\n",
    "            print(f\"Trying tol: {tol}\")\n",
    "            for max_iter in max_iters:\n",
    "                if valid_max_iter is None:\n",
    "                    valid_max_iter = max_iter\n",
    "                else:\n",
    "                    if valid_tol is None:\n",
    "                        continue\n",
    "                    if len(nvalid) > 0:\n",
    "                        print(f\"valid max_iter from training: {valid_max_iter}\")\n",
    "                        break\n",
    "                print(f\"Trying max_iter: {max_iter}\")\n",
    "                for j, n in enumerate(nvals):\n",
    "                    if valid_max_iter is None or valid_tol is None:\n",
    "                        break\n",
    "                    print(f\"{j}\")\n",
    "                    train_score = None\n",
    "                    validation_score = None\n",
    "                    try:\n",
    "                        model = MNMM(n_components=n,\n",
    "                                     random_state = rs,\n",
    "                                     max_iter=valid_max_iter,\n",
    "                                     rtol=valid_tol)\n",
    "                        scores = cross_validation(model, X, cv=5)\n",
    "                        print(f\"&&&&& {scores}\")\n",
    "                        trainNLL.append(np.mean(scores['train_score']))\n",
    "                        validNLL.append(np.mean(scores['test_score']))\n",
    "                        nvalid.append(f\"{j}\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        break\n",
    "#                     except ValueError as e:\n",
    "#                         warnings.warn(f\"reg_covar {reg_covar} is too small.\")\n",
    "#                         valid_reg_covar = None\n",
    "#                         valid_max_iter = None\n",
    "#                         trainNLL = []\n",
    "#                         validNLL = []\n",
    "#                         nvalid = []\n",
    "#                         break\n",
    "#                     except ConvergenceWarning:\n",
    "#                         warnings.warn(f\"max_iter {max_iter} is too small to reach convergence.\")\n",
    "#                         valid_max_iter = None\n",
    "#                         trainNLL = []\n",
    "#                         validNLL = []\n",
    "#                         nvalid = []\n",
    "#                         break\n",
    "    return trainNLL, validNLL, nvalid, valid_max_iter, valid_tol\n",
    "\n",
    "\n",
    "\n",
    "# hyperparams = dict(max_iters=[10, 100, 1000, 10000, 100000],\n",
    "#                    reg_covars=[1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "#                    nvals=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40 , 50),\n",
    "#                    cov_types=['full', 'spherical', 'diag', 'tied'])\n",
    "_trainNLL, _validNLL, _nvalid, _valid_max_iter, _valid_tol = train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c821ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Elbow Method For Optimal n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create elbow plot\n",
    "\n",
    "# fig,ax = plt.subplots(2, 2, figsize=(15,15))\n",
    "\n",
    "\n",
    "# for i, cov_type in enumerate(cov_types):\n",
    "#     row_num = int(i/2)\n",
    "#     col_num = i%2\n",
    "#     if len(ax.shape) > 1:\n",
    "#         line1 = ax[row_num, col_num].plot(nvals, trainNLL[(0 + (i * 14)):(14 + (i * 14))], 'bx-')\n",
    "#         line2 = ax[row_num, col_num].plot(nvals, validNLL[(0 + (i * 14)):(14 + (i * 14))], 'ro-')\n",
    "#         ax[row_num, col_num].set_xlabel('K')\n",
    "#         ax[row_num, col_num].set_ylabel('NLL')\n",
    "#         ax[row_num, col_num].title.set_text(cov_type.upper())\n",
    "#         ax[row_num, col_num].legend(['training', 'validation'])\n",
    "#     else:\n",
    "#         line1 = ax[col_num].plot(nvals, trainNLL[(0 + (i * 14)):(14 + (i * 14))], 'bx-')\n",
    "#         line2 = ax[col_num].plot(nvals, validNLL[(0 + (i * 14)):(14 + (i * 14))], 'ro-')\n",
    "#         ax[col_num].set_xlabel('K')\n",
    "#         ax[col_num].set_ylabel('NLL')\n",
    "#         ax[col_num].title.set_text(cov_type.upper())\n",
    "#         ax[col_num].legend(['training', 'validation'])\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(_nvalid, _trainNLL, 'bx-')\n",
    "plt.plot(_nvalid, _validNLL, 'ro-')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('NLL')\n",
    "plt.title('Elbow Method For Optimal n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bic_index = validateAIC.index(min(validateAIC))\n",
    "hyperparams = nvalid[min_bic_index].split('-')\n",
    "cov_type = cov_types[int(hyperparams[0])]\n",
    "components = nvals[int(hyperparams[1])]\n",
    "print(cov_type, components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianMixture(n_components=components, covariance_type=cov_type, random_state = 1729, max_iter=1000, reg_covar=1e-4)\n",
    "model.fit(X)\n",
    "print(X.shape)\n",
    "Xn = model.sample(382154)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87583ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.converged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the distribution of the features using histogram\n",
    "\n",
    "fig_rows = int(n_features/2) if n_features % 2 == 0 else int(n_features/2 + 1)\n",
    "fig_columns = 2\n",
    "bins = 50\n",
    "\n",
    "fig,ax = plt.subplots(fig_rows, fig_columns, figsize=(15,15))\n",
    "for feature in range(n_features):\n",
    "    row_num = int(feature/fig_columns)\n",
    "    col_num = feature%fig_columns\n",
    "    if len(ax.shape) > 1:\n",
    "        ax[row_num, col_num].hist([X[:, feature], Xn[0][:, feature]],\n",
    "                                  bins=bins,\n",
    "                                  label=['original', 'synthetic'])\n",
    "        ax[row_num, col_num].legend(['original', 'synthetic'])\n",
    "\n",
    "    else:\n",
    "        ax[col_num].hist([X[:, feature], Xn[0][:, feature]],\n",
    "                         bins=bins, \n",
    "                         label=['original', 'synthetic'])\n",
    "        ax[col_num].legend(['original', 'synthetic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "for col in range(n_features):\n",
    "    pvalue = ks_2samp(data1=X[:, col], data2=Xn[0][:, col], alternative='two-sided')\n",
    "    print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "n0, bins0, patches0 = ax.hist(X[:, 0],\n",
    "                              bins=100,\n",
    "                              histtype='step',\n",
    "                              cumulative=True,\n",
    "                              label='Original')\n",
    "n1, bins1, patches1 = ax.hist(Xn[0][:, 0],\n",
    "                              bins=bins,\n",
    "                              histtype='step',\n",
    "                              cumulative=True,\n",
    "                              label='Synthetic')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='lower center')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
